{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b27279-15fd-4ba9-a955-65b7ae6aba73",
   "metadata": {},
   "source": [
    "### Proyecto BeautifulSoup\n",
    "Debes elegir una página para scrapear con BeatifulSoup y guardar los datos en formato .csv, .json o el formato que desees pero es importante que tengas en cuenta que:\n",
    "\n",
    "Sin login ni captchas: facilitan el scraping sin complicaciones.\n",
    "Estructura HTML clara y consistente: que puedan localizar elementos de forma fácil\n",
    "Páginas con paginación opcional, si es posible: para practicar whiles y extracción en varias páginas.\n",
    "Atentos a algún aviso de tipo legal\n",
    "No usar e-commerce como Amazon, Ebay, usan bloqueos, mucho JavaScript y suelen prohibir scraping.\n",
    "Las redes sociales suelen dar problemas por temas de privacidad\n",
    "Lo mejor son páginas de pequeños comercios\n",
    "Vuelca los datos en .json y aplícalo cuatro funciones de Pandas que no hayamos visto en clase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8788329b-ff94-4264-bbdb-acbb96173e72",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b5bef8-22dc-4d7e-ab5b-a99d0dae39f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Título   Año Ganados Nominados\n",
      "0           Anora  2024       5         6\n",
      "1   The Brutalist  2024       3        10\n",
      "2    Emilia Pérez  2024       2        13\n",
      "3          Wicked  2024       2        10\n",
      "4  Dune: Part Two  2024       2         5\n",
      "Datos guardados en 'oscar_winners.csv' y 'oscar_winners.json'\n"
     ]
    }
   ],
   "source": [
    "import requests # descargar la pagina web\n",
    "from bs4 import BeautifulSoup # con esto extraemos los datos del HTML\n",
    "import pandas as pd \n",
    "\n",
    "'''Los servidores web muchas veces bloquean peticiones automáticas si creen que no vienen de un navegador\n",
    "Para evitar eso, añadimos una cabecera User-Agent, \n",
    "que le dice al servidor “hola, soy un programa que solo está leyendo la web, \n",
    "no haciendo nda raor\n",
    "'''\n",
    "def estado(code):\n",
    "    if code == 200:\n",
    "        return \"Conexión exitosa\"\n",
    "    else:\n",
    "        return f\"Error: código {code}\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"MiScraperEducativo/1.0 (+https://tusitio.com/contacto)\"\n",
    "}\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_Academy_Award%E2%80%93winning_films\"\n",
    "response = requests.get(url, headers=headers) #pedimos la pagina\n",
    "state = estado(response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    #    bsuycan su rtbala\n",
    "    tabla = soup.find(\"table\", class_=\"wikitable\")\n",
    "\n",
    "    filas = tabla.find_all(\"tr\")[1:]\n",
    "\n",
    "    titulos = []\n",
    "    año = []\n",
    "    ganados = []\n",
    "    nominados = []\n",
    "\n",
    "    #Recorrer cada fila y extraer celdas\n",
    "    for fila in filas:\n",
    "        celdas = fila.find_all([\"td\", \"th\"])\n",
    "        #los gheaders serian ....\n",
    "        #TODO  cmabiar por bucle\n",
    "        if len(celdas) >= 4:\n",
    "            titulo = celdas[0].get_text(strip=True)\n",
    "            año_film = celdas[1].get_text(strip=True)\n",
    "            ganados_str = celdas[2].get_text(strip=True)\n",
    "            nominados_str = celdas[3].get_text(strip=True)\n",
    "\n",
    "    \n",
    "            titulos.append(titulo)\n",
    "            año.append(año_film)\n",
    "            ganados.append(ganados_str)\n",
    "            nominados.append(nominados_str)\n",
    "    df = pd.DataFrame({\n",
    "        \"Título\": titulos,\n",
    "        \"Año\": año,\n",
    "        \"Ganados\": ganados,\n",
    "        \"Nominados\": nominados\n",
    "    })\n",
    "    print(df.head())\n",
    "    df.to_csv(\"oscar_winners.csv\", index=False, encoding=\"utf-8\")\n",
    "    df.to_json(\"oscar_winners.json\", orient=\"records\", indent=4, force_ascii=False)\n",
    "\n",
    "    print(\"Datos guardados en 'oscar_winners.csv' y 'oscar_winners.json'\")\n",
    "else:\n",
    "    print(\"Error al acceder a la página\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7125956-808a-43d7-868a-baec06d2ad50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1f7815-f28c-4c76-a736-a82febe9ca8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af262ead-8649-4a52-ae4f-73b8d7de1030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
